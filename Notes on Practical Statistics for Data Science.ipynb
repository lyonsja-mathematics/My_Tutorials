{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b703dfd-4abd-4f4a-b2e8-b17aaf1c6664",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### What is the difference between a blind study and a double blind study?\n",
    "\n",
    "A blind study is when the subject does not know which treatment he receives; a double blind study refers to when neither the subject and the data collectors, e.g. doctors or nurses, know which treatment is administered."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87db8ded-35a1-4de4-9388-e72331e50593",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### How would you determine that there is true correlation between two varibales rather than simply random chance?\n",
    "The purpose of hypothesis tests, also known as significance tests, is to help you learn if random chance might be responsible for an observed phenomena; the hypothesis that chance is responsible is called the null hypothesis. Hypothesis test can be either one-way or two-way. One way is for A is better than B tests; two way is for A is different to B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15252e4b-4ebe-4c76-9e77-9b266a3906f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### How does a permutation test work?\n",
    "\n",
    "A permutation test involves combining the results from groups A, B and C into a single dataset; take a random sample (without replacement) the size of A, another the size of B and another the size of C; whichever statistic was calculated for the original samples, calculate for the random samples, repeat multiple times. If the observed difference lies within the permutated difference then it is within the range of what chance might produce, in other words it is statistically insignificant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6535b05-a026-4fa5-a283-199341e7f195",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### What would a p-value of 0.01 suggest?\n",
    "\n",
    "The frequency with which the chance model produces a result more extreme than the observed result is the p-value. So $p=0.01$ means that only 1\\% of model predictions are more extreme than the observed results. Usually, 95\\% is the standard significance level for statistical models, so if the p-values is less than 0.025 the model can be considered reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e703a5-3707-4cb0-8689-ac7add98a9fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Suppose there is a non-linear relationship between predictor and response, how could your regression model be extended to capture the non-linear effects?\n",
    "\n",
    "Splines. Polynomial regression is also an option but that can only capture a certain amount of non-linearity so that's ok for a quadratic relationship but for higher order terms you get a \"wiggliness\" in your regression which isn't useful. Splines are piecewise continuous polymernomial segments that allow us to smoothly interpolate between data points and are a better approach. The polynomial segments are connected at a series of fixed points in the predictor variable, these are called knots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da2d5d9-9cf8-4c6f-9471-94a9d02e952a",
   "metadata": {},
   "source": [
    "### How should you decide whether a model should have more or fewer predictors?\n",
    "\n",
    "A simpler statistical model is preferable to a more complicated one. The AIC is a statistical metric that penalizes the addition of unnecessary predictors to a statistical model. For a data set of $n$ records and $P$ variables\n",
    "$$\n",
    "\\text{AIC} = 2P + n \\log \\left( \\frac{\\text{RSS}}{n}\\right),\n",
    "$$\n",
    "where RSS is the residual sum of squares\n",
    "$$\n",
    "\\text{RSS} = \\sum_{i=1}^n (Y_i - \\hat{Y_i})^2.\n",
    "$$\n",
    "The model with the smallest AIC is best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179f285b-9aa4-40dc-bbfa-2f5e8040602b",
   "metadata": {},
   "source": [
    "### Is there a distinction between machine learning and classical statistics?\n",
    "\n",
    "There is very little difference between them. Machine learning is about creating efficient algorithms which can be applied to large data sets for the purposes of predicting outcomes. Regression and classification modelling are examples of machine learning methods, both involves training the model on known data then using it to predict outcomes in an unknown data set, this is called supervised learning methods. Classical statistics, strictly speaking, is more about probability theory and the underlying structure of the model; bagging and random forest methods closer to statistics than machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76ae2cb-e8d3-4ed2-854d-c01767bb5e9c",
   "metadata": {},
   "source": [
    "### What technique would you use if you needed to predict a binary outcome?\n",
    "\n",
    "K-nearest neighbors would be the best approach. In a data set, a neighbor is just a record that has similar predictors to the test record. The KNN method just finds K records that are most similar to our test, looks at the outcome of those K and it takes the most common outcome as its prediction for the test outcome. Decision trees are another method for predicting a binary outcome. The idea of decision trees is to repeatedly divide and subdivide the data with the aim of making the outcome after each subdivision more and more homogenous; you will end up a set of if-else rules that will guide a test record to a predicted outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c93dbbd-ffb4-4dc4-9faf-907c7ad35725",
   "metadata": {},
   "source": [
    "### Why should predictors be standardized when using the K nearest neighbors?\n",
    "\n",
    "The KNN method calculates the Euclidean distance of the test vector to each record in the training set then takes the K records with the smallest distance. This is problematic if the predictors are on a different scale to others. Suppose we have two predictors in our model $y \\tilde x + w$, the euclidean distance is \n",
    "$$\n",
    "d=\\sqrt{(y-x)^2 + (y-w)^2}.\n",
    "$$\n",
    "But if $0 \\leq x \\leq 1$ and $0 \\leq w \\leq 100,000$ then\n",
    "$$\n",
    "d \\approx \\left|y-w\\right|.\n",
    "$$\n",
    "This can be fixed by standardizing the variables, i.e. subtract the mean and divide by standard deviation,\n",
    "$$\n",
    "w^* = \\frac{w - \\overline{w}}{s}.\n",
    "$$\n",
    "The standardized distance is\n",
    "$$\n",
    "d = \\sqrt{(y-x^*)^2 + (y - w^*)^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28477467-b6fb-4509-b33c-0a7fe4119a20",
   "metadata": {},
   "source": [
    "### How would you decide which number to use as K?\n",
    "\n",
    "K should be an odd number to avoid ties. If you're dealing with a data set that is highly structured and little noise then a small K is best, data sets with more noise and less structure should have a larger K but no more than 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f422455-7745-4885-923c-52a6343e6dc7",
   "metadata": {},
   "source": [
    "### In the design of a tree model, how is homogeneity measured?\n",
    "\n",
    "Homogeneity, also known as class purity, of a partition can be measured by either the GINI imputity (not GINI coefficient) or entropy. If the proportion of misclassified records in partition $A$ is $p$ then the GINI impurity is\n",
    "$$\n",
    "I(A) = p(1-p),\n",
    "$$\n",
    "and entropy is\n",
    "$$\n",
    "I(A) = -p \\log_2 (p) - (1-p)\\log_2(1-p).\n",
    "$$\n",
    "The proposed partition with the lowest GINI impurity or entropy is best for the tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b93a0b-ec10-46c4-9d59-1fa9f3d74cf1",
   "metadata": {},
   "source": [
    "### What is meant by bootstrapping in data science?\n",
    "\n",
    "Repeatedly taking a random sample from a known data set (with replacement) to generate a sampling distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e74013-e2f6-4f7f-b661-8ad986c1cd36",
   "metadata": {},
   "source": [
    "### In the calculation of standard deviation, why is the divisor $n-1$ rather than $n$?\n",
    "\n",
    "We divide by the degrees of freedom which is $n-1$ which is the difference between the number of records and number of constraints. Consider the day of the week as a variable, if you that it is not Monday, not Tuesday, not Wednesday, not Thursday, not Saturday and not Sunday then you know the variable must be Friday so there are six degrees of freedom for this variable. Most data science problems will typically involve a large number of records so this distinction is not very important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ba3394-8315-431c-87b7-28413ebdcd9f",
   "metadata": {},
   "source": [
    "### How is Pearson's correlation coefficient calculated?\n",
    "\n",
    "For variables $x_i$ and $y_i$, $i \\in [1,n]$\n",
    "$$\n",
    "P = \\frac{\\sum_i (x_i - \\overline{x})(y_i - \\overline{y})}{(n-1) s_x s_y},\n",
    "$$\n",
    "where $s_x$ and $s_y$ are the standard deviation of $x$ and $y$ respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2e08dc-914c-46e4-bdc6-50b55adc7169",
   "metadata": {},
   "source": [
    "# Chapter 7: Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ae7793-d694-4430-99c4-bec9635b23d2",
   "metadata": {},
   "source": [
    "### What is cross-validation?\n",
    "\n",
    "Split the data into a number of different groups, called folds. For each fold, a model is trained on the data not in the fold then tested on the data in the fold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737496e2-deba-49bc-80f7-3b5ddf743850",
   "metadata": {},
   "source": [
    "### What is the difference between supervised and unsupervised learning?\n",
    "\n",
    "Statistical methods that extract meaning from data without training a model on labelled data is called unsupervised learning. Supervised learning is when a model is trained on data to predict an outcome from a set of predictor variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea85b73b-33bf-4f31-8596-26856968a6e6",
   "metadata": {},
   "source": [
    "### How does Principal Component Analysis work?\n",
    "\n",
    "The idea of PCA is to reduce the number of numerical predictor variables to a smaller set of predictors, called principal components, which are a weighted linear combination of the predictors. The principal components explain most of the variability of the full set of predictors and thereby reducing the dimension of the data. For example, suppose there are 2 variables $X_1$ and $X_2$ and therefore two principal components\n",
    "\n",
    "\\begin{align}\n",
    "Z_1 = w_{1,1} X_1 + w_{1,2} X_2,\\\\\n",
    "Z_2 = w_{2,1} X_1 + w_{2,2} X_2,\n",
    "\\end{align}\n",
    "\n",
    "the weights $w_{i,1}$, $w_{i,2}$ are called the component loadings.The first principal component, $Z_1$, is the linear combination that best explains the total variation; $Z_2$ is orthogonal to $Z_1$ and explains as much of the remaining variation as it can."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42653b4-5df6-469a-acf6-74f0261b0239",
   "metadata": {},
   "source": [
    "### How is the covariance matrix of two variables $x$ and $z$ calculated?\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\Sigma} = \\left[\n",
    "\\begin{matrix}\n",
    "s_x^2 & s_{x,z}\\\\\n",
    "s_{z,x} & s_z^2\n",
    "\\end{matrix}\n",
    "\\right],\n",
    "\\end{equation}\n",
    "\n",
    "where covarianve is calculated as\n",
    "\\begin{equation}\n",
    "s_{x,z} = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(z_i - \\overline{z})}{n-1}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c66b8-fa65-4a7a-969f-726bac570a86",
   "metadata": {},
   "source": [
    "### How would you go about splitting a data set of two variables $x$ and $y$ into four clusters?\n",
    "\n",
    "Each record $(x_i,y_i)$ must be assigned to cluster $k$ with $n_k$ the number of records in cluster $k$. The cluster mean is\n",
    "\\begin{equation}\n",
    "(\\overline{x_k},\\overline{y_k}) = \\left( \\frac{1}{n_k} \\sum_{i} x_i, \\frac{1}{n_k} \\sum_{i} y_i \\right),\n",
    "\\end{equation}\n",
    "\n",
    "for all $i$ in cluster $k$. The sum of squares of cluster $k$ is\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{SS}_k = \\sum_i (x_i - \\overline{x_k})^2 + (y_i - \\overline{y_k})^2.\n",
    "\\end{equation}\n",
    "\n",
    "Which cluster should $(x_i,y_i)$ be assigned to? The ideal assignment is such that the total sum of squares\n",
    "\\begin{equation}\n",
    "\\sum_{k=1}^4 \\text{SS}_k\n",
    "\\end{equation}\n",
    "\n",
    "is minimized. This can be done in R via the \\texttt{kmeans} function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d3e616-4677-4b17-bf86-b4368bdbc29d",
   "metadata": {},
   "source": [
    "### How do hierarchical clustering methods decide which number of cluster to use?\n",
    "\n",
    "Hierarchical clustering calculates the *Bayesian Information Criterial* (BIC) for a number of clusters and selects the one with the greatest negative value. BIC is similar to AIC, there is a penalty for the number of parameters in the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
